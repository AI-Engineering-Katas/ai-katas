"use strict";(self.webpackChunktech_docs=self.webpackChunktech_docs||[]).push([[3664],{7814:(i,n,e)=>{e.r(n),e.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>u,frontMatter:()=>d,metadata:()=>s,toc:()=>r});const s=JSON.parse('{"id":"capabilities/audio-understanding","title":"Audio Understanding","description":"Audio Understanding is the capability to analyze, process, and extract meaning from audio signals using digital signal processing and machine learning techniques.","source":"@site/docs/capabilities/audio-understanding.md","sourceDirName":"capabilities","slug":"/capabilities/audio-understanding","permalink":"/ai-katas/capabilities/audio-understanding","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"audio-understanding","title":"Audio Understanding","sidebar_label":"Audio Understanding"},"sidebar":"defaultSidebar","previous":{"title":"Audio Generation","permalink":"/ai-katas/capabilities/audio-generation"},"next":{"title":"Automated Decision Making","permalink":"/ai-katas/capabilities/automated-decision-making"}}');var t=e(4848),a=e(8453);const d={id:"audio-understanding",title:"Audio Understanding",sidebar_label:"Audio Understanding"},l="Audio Understanding",o={},r=[{value:"Related Solution Fields",id:"related-solution-fields",level:2},{value:"Overview",id:"overview",level:2},{value:"Applications",id:"applications",level:2}];function c(i){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",ul:"ul",...(0,a.R)(),...i.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"audio-understanding",children:"Audio Understanding"})}),"\n",(0,t.jsx)(n.p,{children:"Audio Understanding is the capability to analyze, process, and extract meaning from audio signals using digital signal processing and machine learning techniques."}),"\n",(0,t.jsx)(n.h2,{id:"related-solution-fields",children:"Related Solution Fields"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"../solutions/speech-recognition",children:"Speech Recognition"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"../solutions/audio-classification",children:"Audio Classification"})}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsx)(n.p,{children:"Audio Understanding enables systems to:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Convert speech to text"}),"\n",(0,t.jsx)(n.li,{children:"Identify speakers and sounds"}),"\n",(0,t.jsx)(n.li,{children:"Analyze acoustic properties"}),"\n",(0,t.jsx)(n.li,{children:"Detect emotions in speech"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"applications",children:"Applications"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Voice assistants"}),"\n",(0,t.jsx)(n.li,{children:"Audio content moderation"}),"\n",(0,t.jsx)(n.li,{children:"Music analysis"}),"\n",(0,t.jsx)(n.li,{children:"Security and surveillance"}),"\n"]})]})}function u(i={}){const{wrapper:n}={...(0,a.R)(),...i.components};return n?(0,t.jsx)(n,{...i,children:(0,t.jsx)(c,{...i})}):c(i)}},8453:(i,n,e)=>{e.d(n,{R:()=>d,x:()=>l});var s=e(6540);const t={},a=s.createContext(t);function d(i){const n=s.useContext(a);return s.useMemo((function(){return"function"==typeof i?i(n):{...n,...i}}),[n,i])}function l(i){let n;return n=i.disableParentContext?"function"==typeof i.components?i.components(t):i.components||t:d(i.components),s.createElement(a.Provider,{value:n},i.children)}}}]);