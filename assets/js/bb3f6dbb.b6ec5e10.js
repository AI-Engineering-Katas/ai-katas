"use strict";(self.webpackChunktech_docs=self.webpackChunktech_docs||[]).push([[3702],{9220:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>r,contentTitle:()=>d,default:()=>u,frontMatter:()=>s,metadata:()=>t,toc:()=>o});const t=JSON.parse('{"id":"capabilities/multi-modal-understanding","title":"Multi-Modal Understanding","description":"Multi-Modal Understanding is the capability to process, analyze, and comprehend information from multiple types of data sources simultaneously.","source":"@site/docs/capabilities/multi-modal-understanding.md","sourceDirName":"capabilities","slug":"/capabilities/multi-modal-understanding","permalink":"/ai-katas/capabilities/multi-modal-understanding","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"multi-modal-understanding","title":"Multi-Modal Understanding","sidebar_label":"Multi-Modal Understanding"},"sidebar":"defaultSidebar","previous":{"title":"Image Understanding","permalink":"/ai-katas/capabilities/image-understanding"},"next":{"title":"Pattern Discovery","permalink":"/ai-katas/capabilities/pattern-discovery"}}');var a=i(4848),l=i(8453);const s={id:"multi-modal-understanding",title:"Multi-Modal Understanding",sidebar_label:"Multi-Modal Understanding"},d="Multi-Modal Understanding",r={},o=[{value:"Related Solution Fields",id:"related-solution-fields",level:2},{value:"Overview",id:"overview",level:2},{value:"Applications",id:"applications",level:2}];function c(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",ul:"ul",...(0,l.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"multi-modal-understanding",children:"Multi-Modal Understanding"})}),"\n",(0,a.jsx)(n.p,{children:"Multi-Modal Understanding is the capability to process, analyze, and comprehend information from multiple types of data sources simultaneously."}),"\n",(0,a.jsx)(n.h2,{id:"related-solution-fields",children:"Related Solution Fields"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"../solutions/cross-modal-learning",children:"Cross-Modal Learning"})}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,a.jsx)(n.p,{children:"Multi-Modal Understanding enables systems to:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Combine different data types"}),"\n",(0,a.jsx)(n.li,{children:"Cross-reference information"}),"\n",(0,a.jsx)(n.li,{children:"Extract unified meaning"}),"\n",(0,a.jsx)(n.li,{children:"Handle mixed-media content"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"applications",children:"Applications"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Visual question answering"}),"\n",(0,a.jsx)(n.li,{children:"Multi-modal search"}),"\n",(0,a.jsx)(n.li,{children:"Mixed-media analysis"}),"\n",(0,a.jsx)(n.li,{children:"Cross-modal retrieval"}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>d});var t=i(6540);const a={},l=t.createContext(a);function s(e){const n=t.useContext(l);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),t.createElement(l.Provider,{value:n},e.children)}}}]);