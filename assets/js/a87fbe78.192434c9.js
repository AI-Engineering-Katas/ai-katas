"use strict";(self.webpackChunktech_docs=self.webpackChunktech_docs||[]).push([[2309],{7435:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>r,contentTitle:()=>c,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>a});const s=JSON.parse('{"id":"solutions/speech-recognition","title":"Speech Recognition","description":"Speech Recognition is a solution for converting spoken language into text using machine learning and signal processing techniques.","source":"@site/docs/solutions/speech-recognition.md","sourceDirName":"solutions","slug":"/solutions/speech-recognition","permalink":"/ai-katas/solutions/speech-recognition","draft":false,"unlisted":false,"editUrl":"https://github.com/ai-katas/ai-building-blocks/tree/main/docs/solutions/speech-recognition.md","tags":[],"version":"current","frontMatter":{"id":"speech-recognition","title":"Speech Recognition","sidebar_label":"Speech Recognition"}}');var t=i(4848),l=i(8453);const o={id:"speech-recognition",title:"Speech Recognition",sidebar_label:"Speech Recognition"},c="Speech Recognition",r={},a=[{value:"Key Capabilities Used",id:"key-capabilities-used",level:2},{value:"Features",id:"features",level:2},{value:"Use Cases",id:"use-cases",level:2},{value:"Technologies",id:"technologies",level:2},{value:"Related Solutions",id:"related-solutions",level:2}];function d(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",ul:"ul",...(0,l.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"speech-recognition",children:"Speech Recognition"})}),"\n",(0,t.jsx)(n.p,{children:"Speech Recognition is a solution for converting spoken language into text using machine learning and signal processing techniques."}),"\n",(0,t.jsx)(n.h2,{id:"key-capabilities-used",children:"Key Capabilities Used"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"../capabilities/audio-understanding",children:"Audio Understanding"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"../capabilities/text-generation",children:"Text Generation"})}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"features",children:"Features"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Real-time transcription"}),"\n",(0,t.jsx)(n.li,{children:"Speaker identification"}),"\n",(0,t.jsx)(n.li,{children:"Noise reduction"}),"\n",(0,t.jsx)(n.li,{children:"Multi-language support"}),"\n",(0,t.jsx)(n.li,{children:"Custom vocabulary handling"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"use-cases",children:"Use Cases"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Voice assistants"}),"\n",(0,t.jsx)(n.li,{children:"Meeting transcription"}),"\n",(0,t.jsx)(n.li,{children:"Subtitle generation"}),"\n",(0,t.jsx)(n.li,{children:"Voice command systems"}),"\n",(0,t.jsx)(n.li,{children:"Call center analytics"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"technologies",children:"Technologies"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Deep neural networks"}),"\n",(0,t.jsx)(n.li,{children:"Hidden Markov Models"}),"\n",(0,t.jsx)(n.li,{children:"Acoustic modeling"}),"\n",(0,t.jsx)(n.li,{children:"Language modeling"}),"\n",(0,t.jsx)(n.li,{children:"Signal processing"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"related-solutions",children:"Related Solutions"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"./audio-classification",children:"Audio Classification"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>c});var s=i(6540);const t={},l=s.createContext(t);function o(e){const n=s.useContext(l);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),s.createElement(l.Provider,{value:n},e.children)}}}]);